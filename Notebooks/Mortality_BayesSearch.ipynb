{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal Gridsearch\n",
    "An Exploration of Bayesian approach to hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from xgboost import XGBRegressor, DMatrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.utils import point_asdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "We use the ILEC 2009-15 Individual Life Insurance Mortality Experience Report data (https://www.soa.org/resources/research-reports/2019/2009-2015-individual-life-mortality/). Cases are restricted between issue age [40,60) and duration < 10. Cases without exposure are omitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [ 'Preferred Indicator',\n",
    "         'Face Amount Band','Gender',\n",
    "         'Smoker Status',\n",
    " 'Insurance Plan',\n",
    " 'Issue Age',\n",
    " 'Duration',\n",
    " 'Attained Age',\n",
    " 'Number of Deaths',\n",
    " 'Policies Exposed',]\n",
    "dat = pd.read_csv('../../scratchpad/2009-15 Data 20180601.txt',nrows=2e6,sep='\\t',usecols=cols)\n",
    "dat = dat[(dat['Issue Age']>=40)&(dat['Issue Age'] <60)&(dat['Duration']<10)]\n",
    "dat = dat[dat['Policies Exposed']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Preferred Indicator</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Smoker Status</th>\n",
       "      <th>Insurance Plan</th>\n",
       "      <th>Issue Age</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Attained Age</th>\n",
       "      <th>Face Amount Band</th>\n",
       "      <th>Number of Deaths</th>\n",
       "      <th>Policies Exposed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>NonSmoker</td>\n",
       "      <td>Term</td>\n",
       "      <td>44</td>\n",
       "      <td>9</td>\n",
       "      <td>52</td>\n",
       "      <td>100000-249999</td>\n",
       "      <td>0</td>\n",
       "      <td>2.660124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>NonSmoker</td>\n",
       "      <td>ULSG</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>1000000-2499999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.364384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>NonSmoker</td>\n",
       "      <td>Term</td>\n",
       "      <td>44</td>\n",
       "      <td>9</td>\n",
       "      <td>52</td>\n",
       "      <td>100000-249999</td>\n",
       "      <td>0</td>\n",
       "      <td>20.324095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>NonSmoker</td>\n",
       "      <td>ULSG</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>1000000-2499999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.871233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>NonSmoker</td>\n",
       "      <td>ULSG</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>2500000-4999999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.172603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Preferred Indicator  Gender Smoker Status Insurance Plan  Issue Age  \\\n",
       "0                    1  Female     NonSmoker           Term         44   \n",
       "1                    1  Female     NonSmoker           ULSG         40   \n",
       "2                    1  Female     NonSmoker           Term         44   \n",
       "3                    1  Female     NonSmoker           ULSG         40   \n",
       "4                    1  Female     NonSmoker           ULSG         40   \n",
       "\n",
       "   Duration  Attained Age  Face Amount Band  Number of Deaths  \\\n",
       "0         9            52     100000-249999                 0   \n",
       "1         2            41   1000000-2499999                 0   \n",
       "2         9            52     100000-249999                 0   \n",
       "3         2            41   1000000-2499999                 0   \n",
       "4         2            41   2500000-4999999                 0   \n",
       "\n",
       "   Policies Exposed  \n",
       "0          2.660124  \n",
       "1          0.364384  \n",
       "2         20.324095  \n",
       "3          0.871233  \n",
       "4          0.172603  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "regs = [ 'Preferred Indicator',\n",
    "         'Face Amount Band','Gender',\n",
    "         'Smoker Status',\n",
    " 'Insurance Plan',\n",
    " 'Issue Age',\n",
    " 'Duration']\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "dat['Face Amount Band'] = labelencoder.fit_transform(dat['Face Amount Band'].astype('category'))\n",
    "dat['Gender'] = labelencoder.fit_transform(dat['Gender'].astype('category'))\n",
    "dat['Smoker Status'] = labelencoder.fit_transform(dat['Smoker Status'].astype('category'))\n",
    "dat['Insurance Plan'] = labelencoder.fit_transform(dat['Insurance Plan'].astype('category'))\n",
    "\n",
    "\n",
    "X_train, X_eval, y_train, y_eval, exp_train, exp_eval = train_test_split(dat[regs],dat['Number of Deaths'], dat['Policies Exposed'],\n",
    "                                                    test_size=.3, random_state=52,\n",
    "                                                    stratify = dat[['Issue Age','Duration','Gender']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Callback Function\n",
    "This function outputs the fit statistics for each test to .csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cb(v,filename = '../Output/tuning_results.csv', verbose = 0):\n",
    "    last_point = v.x_iters[-1]\n",
    "    p = point_asdict(opt.search_spaces, last_point)\n",
    "    if verbose>0:\n",
    "        print(\"Tried {0}, score ={1}\".format(p,opt.cv_results_.get('mean_test_score')[-1]))\n",
    "    df_cv = pd.DataFrame(opt.cv_results_.get('params')).\\\n",
    "    assign(score = opt.cv_results_.get('mean_test_score'))\n",
    "    df_cv = df_cv.assign(train_score = opt.cv_results_.get('mean_train_score'))\n",
    "    df_cv['train_test_diff'] = df_cv.train_score-df_cv.score\n",
    "    if verbose>0:\n",
    "        print(\"best score = {0} @ diff = {1}\".format(df_cv.score.max(),df_cv[df_cv.score==df_cv.score.max()].train_test_diff.min()))\n",
    "    if filename:\n",
    "        df_cv.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.6s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.6s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.6s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   5.9s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   5.9s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   5.9s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.7s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.7s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.7s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   3.3s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.9s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   3.0s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.4s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.3s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.4s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.1s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.1s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.1s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.6s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.6s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.6s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   9.2s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   9.0s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   9.1s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   6.3s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   5.7s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   6.0s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   4.4s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   4.4s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   4.4s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   5.9s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   5.9s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   5.9s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   3.6s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   3.6s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   3.8s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.9s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.9s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.9s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.8s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.8s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.8s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.4s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.4s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.4s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.7s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.7s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.7s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   3.5s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   3.6s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   3.6s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   4.5s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   4.5s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   5.0s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   9.1s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   9.1s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   9.2s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   3.6s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   3.7s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   3.7s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.5s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.4s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.4s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.9s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.9s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.9s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.9s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.9s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.9s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.1s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.1s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.1s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.9s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.9s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.9s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   9.1s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   9.1s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   9.1s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.8s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.8s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.8s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=3,\n",
       "              estimator=Pipeline(steps=[('model',\n",
       "                                         XGBRegressor(base_score=None,\n",
       "                                                      booster=None,\n",
       "                                                      colsample_bylevel=None,\n",
       "                                                      colsample_bynode=None,\n",
       "                                                      colsample_bytree=None,\n",
       "                                                      gamma=None, gpu_id=None,\n",
       "                                                      importance_type='gain',\n",
       "                                                      interaction_constraints=None,\n",
       "                                                      learning_rate=None,\n",
       "                                                      max_delta_step=None,\n",
       "                                                      max_depth=None,\n",
       "                                                      min_child_weight=None,\n",
       "                                                      missing=nan,\n",
       "                                                      monotone_constraints=Non...\n",
       "              n_iter=30, return_train_score=True,\n",
       "              search_spaces={'model__gamma': (1e-06, 10.0, 'log-uniform'),\n",
       "                             'model__learning_rate': Real(low=0.005, high=0.3, prior='uniform', transform='identity'),\n",
       "                             'model__max_depth': Integer(low=2, high=5, prior='uniform', transform='identity'),\n",
       "                             'model__n_estimators': Categorical(categories=(10, 50, 100, 200, 500), prior=None),\n",
       "                             'model__objective': ['count:poisson']})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    steps = [('model', XGBRegressor())],verbose = True\n",
    ")\n",
    "\n",
    "opt = BayesSearchCV(\n",
    "    pipe,\n",
    "    {\n",
    "        'model__objective':['count:poisson'],\n",
    "        'model__n_estimators': Categorical([10,50,100,200,500]),\n",
    "        'model__gamma': (1e-6, 1e+1, 'log-uniform'),\n",
    "        'model__max_depth': Integer(2, 5),  # integer valued parameter\n",
    "        'model__learning_rate': Real(0.005,.3),  # categorical parameter\n",
    "    },\n",
    "    fit_params = {\n",
    "        'model__base_margin':np.log(exp_train)\n",
    "    },\n",
    "    n_iter=30,\n",
    "    cv=3,\n",
    "    return_train_score = True\n",
    ")\n",
    "\n",
    "opt.fit(X_train,y_train,callback = cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   5.8s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   5.8s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   6.0s\n",
      "Tried OrderedDict([('model__gamma', 0.0011932197403764064), ('model__learning_rate', 0.1918035907459515), ('model__max_depth', 3), ('model__n_estimators', 500), ('model__objective', 'count:poisson')]), score =-0.0068668058031450974\n",
      "best score = -0.0068668058031450974 @ diff = 0.0009763767980608745\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.4s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.3s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.3s\n",
      "Tried OrderedDict([('model__gamma', 0.00034319605651276895), ('model__learning_rate', 0.15244126415185713), ('model__max_depth', 3), ('model__n_estimators', 200), ('model__objective', 'count:poisson')]), score =-0.006877313467068639\n",
      "best score = -0.0068668058031450974 @ diff = 0.0009763767980608745\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.1s\n",
      "Tried OrderedDict([('model__gamma', 4.273772408689987e-06), ('model__learning_rate', 0.19897835642061412), ('model__max_depth', 3), ('model__n_estimators', 10), ('model__objective', 'count:poisson')]), score =-2.818586406497918\n",
      "best score = -0.0068668058031450974 @ diff = 0.0009763767980608745\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.1s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.3s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.2s\n",
      "Tried OrderedDict([('model__gamma', 0.00020095139643496054), ('model__learning_rate', 0.006454625674634838), ('model__max_depth', 4), ('model__n_estimators', 200), ('model__objective', 'count:poisson')]), score =-5.819636696944915\n",
      "best score = -0.0068668058031450974 @ diff = 0.0009763767980608745\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.6s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.6s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.6s\n",
      "Tried OrderedDict([('model__gamma', 2.199679724715545), ('model__learning_rate', 0.21265728798903683), ('model__max_depth', 3), ('model__n_estimators', 50), ('model__objective', 'count:poisson')]), score =-0.0038190709156654726\n",
      "best score = -0.0038190709156654726 @ diff = 8.948676641929365e-05\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.5s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.5s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.4s\n",
      "Tried OrderedDict([('model__gamma', 0.06525083992611463), ('model__learning_rate', 0.13598439308397844), ('model__max_depth', 4), ('model__n_estimators', 100), ('model__objective', 'count:poisson')]), score =-0.006212759155233425\n",
      "best score = -0.0038190709156654726 @ diff = 8.948676641929365e-05\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.4s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.3s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.3s\n",
      "Tried OrderedDict([('model__gamma', 3.4641090659474705e-06), ('model__learning_rate', 0.1465556395443512), ('model__max_depth', 3), ('model__n_estimators', 200), ('model__objective', 'count:poisson')]), score =-0.006878232865479486\n",
      "best score = -0.0038190709156654726 @ diff = 8.948676641929365e-05\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.7s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.7s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.7s\n",
      "Tried OrderedDict([('model__gamma', 1.4839133599092285), ('model__learning_rate', 0.2433584069288529), ('model__max_depth', 4), ('model__n_estimators', 50), ('model__objective', 'count:poisson')]), score =-0.005418349535702919\n",
      "best score = -0.0038190709156654726 @ diff = 8.948676641929365e-05\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.4s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.4s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.4s\n",
      "Tried OrderedDict([('model__gamma', 0.009162886622134074), ('model__learning_rate', 0.16185232594047488), ('model__max_depth', 3), ('model__n_estimators', 200), ('model__objective', 'count:poisson')]), score =-0.006860617411831473\n",
      "best score = -0.0038190709156654726 @ diff = 8.948676641929365e-05\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.2s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.2s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.2s\n",
      "Tried OrderedDict([('model__gamma', 2.6894387596831828e-05), ('model__learning_rate', 0.1886435085224953), ('model__max_depth', 3), ('model__n_estimators', 100), ('model__objective', 'count:poisson')]), score =-0.007018589814968705\n",
      "best score = -0.0038190709156654726 @ diff = 8.948676641929365e-05\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=3,\n",
       "              estimator=Pipeline(steps=[('model',\n",
       "                                         XGBRegressor(base_score=None,\n",
       "                                                      booster=None,\n",
       "                                                      colsample_bylevel=None,\n",
       "                                                      colsample_bynode=None,\n",
       "                                                      colsample_bytree=None,\n",
       "                                                      gamma=None, gpu_id=None,\n",
       "                                                      importance_type='gain',\n",
       "                                                      interaction_constraints=None,\n",
       "                                                      learning_rate=None,\n",
       "                                                      max_delta_step=None,\n",
       "                                                      max_depth=None,\n",
       "                                                      min_child_weight=None,\n",
       "                                                      missing=nan,\n",
       "                                                      monotone_constraints=Non...\n",
       "              return_train_score=True,\n",
       "              search_spaces={'model__gamma': (1e-06, 10.0, 'log-uniform'),\n",
       "                             'model__learning_rate': Real(low=0.005, high=0.3, prior='uniform', transform='identity'),\n",
       "                             'model__max_depth': Integer(low=2, high=5, prior='uniform', transform='identity'),\n",
       "                             'model__n_estimators': Categorical(categories=(10, 50, 100, 200, 500), prior=None),\n",
       "                             'model__objective': ['count:poisson']})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_cb = partial(cb,filename='../Output/tuning_results_EI.csv',verbose = 1)\n",
    "opt = BayesSearchCV(\n",
    "    pipe,\n",
    "    {\n",
    "        'model__objective':['count:poisson'],\n",
    "        'model__n_estimators': Categorical([10,50,100,200,500]),\n",
    "        'model__gamma': (1e-6, 1e+1, 'log-uniform'),\n",
    "        'model__max_depth': Integer(2, 5),  # integer valued parameter\n",
    "        'model__learning_rate': Real(0.005,.3),  # categorical parameter\n",
    "    },\n",
    "    fit_params = {\n",
    "        'model__base_margin':np.log(exp_train)\n",
    "    },\n",
    "    n_iter=10,\n",
    "    cv=3,\n",
    "    return_train_score = True,\n",
    "    optimizer_kwargs = {'acq_func':'EI','acq_optimizer_kwargs' :{'xi': 0.2}}\n",
    ")\n",
    "\n",
    "opt.fit(X_train,y_train,callback = my_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.6s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.6s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.6s\n",
      "Tried OrderedDict([('model__gamma', 0.01248587313576065), ('model__learning_rate', 0.15771355774135823), ('model__max_depth', 3), ('model__n_estimators', 50), ('model__objective', 'count:poisson')]), score =0.00032010033033751394\n",
      "best score = 0.00032010033033751394 @ diff = 0.00010017504357413544\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.2s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.2s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.2s\n",
      "Tried OrderedDict([('model__gamma', 0.0008698173501517189), ('model__learning_rate', 0.18324885893452741), ('model__max_depth', 3), ('model__n_estimators', 100), ('model__objective', 'count:poisson')]), score =-0.007026142784461425\n",
      "best score = 0.00032010033033751394 @ diff = 0.00010017504357413544\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.8s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.8s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.8s\n",
      "Tried OrderedDict([('model__gamma', 0.00010544030391230139), ('model__learning_rate', 0.24943099280897518), ('model__max_depth', 5), ('model__n_estimators', 100), ('model__objective', 'count:poisson')]), score =-0.00682111140482062\n",
      "best score = 0.00032010033033751394 @ diff = 0.00010017504357413544\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.6s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.6s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.6s\n",
      "Tried OrderedDict([('model__gamma', 0.4330011581601289), ('model__learning_rate', 0.17970801494231425), ('model__max_depth', 3), ('model__n_estimators', 50), ('model__objective', 'count:poisson')]), score =-0.0007892144504499905\n",
      "best score = 0.00032010033033751394 @ diff = 0.00010017504357413544\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.5s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.5s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.8s\n",
      "Tried OrderedDict([('model__gamma', 0.009433397527026838), ('model__learning_rate', 0.2977539972789081), ('model__max_depth', 4), ('model__n_estimators', 100), ('model__objective', 'count:poisson')]), score =-0.0068247884856482335\n",
      "best score = 0.00032010033033751394 @ diff = 0.00010017504357413544\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.7s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.7s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.7s\n",
      "Tried OrderedDict([('model__gamma', 0.05967372525692374), ('model__learning_rate', 0.15793562991238363), ('model__max_depth', 4), ('model__n_estimators', 50), ('model__objective', 'count:poisson')]), score =0.00043319406745690836\n",
      "best score = 0.00043319406745690836 @ diff = 0.00022660803377645233\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.4s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.3s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.3s\n",
      "Tried OrderedDict([('model__gamma', 8.013143162453098), ('model__learning_rate', 0.1805765132797212), ('model__max_depth', 3), ('model__n_estimators', 200), ('model__objective', 'count:poisson')]), score =-0.007286192102457547\n",
      "best score = 0.00043319406745690836 @ diff = 0.00022660803377645233\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.3s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.3s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.4s\n",
      "Tried OrderedDict([('model__gamma', 1.151854333987857e-05), ('model__learning_rate', 0.13247181649514586), ('model__max_depth', 3), ('model__n_estimators', 200), ('model__objective', 'count:poisson')]), score =-0.006895078009034738\n",
      "best score = 0.00043319406745690836 @ diff = 0.00022660803377645233\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.1s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.1s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.1s\n",
      "Tried OrderedDict([('model__gamma', 1.2223189717934215), ('model__learning_rate', 0.04736952494964594), ('model__max_depth', 3), ('model__n_estimators', 100), ('model__objective', 'count:poisson')]), score =-0.13122979456447303\n",
      "best score = 0.00043319406745690836 @ diff = 0.00022660803377645233\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.8s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.7s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.8s\n",
      "Tried OrderedDict([('model__gamma', 8.604014974405091), ('model__learning_rate', 0.15367988365870516), ('model__max_depth', 5), ('model__n_estimators', 100), ('model__objective', 'count:poisson')]), score =-0.007011475913110602\n",
      "best score = 0.00043319406745690836 @ diff = 0.00022660803377645233\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=3,\n",
       "              estimator=Pipeline(steps=[('model',\n",
       "                                         XGBRegressor(base_score=None,\n",
       "                                                      booster=None,\n",
       "                                                      colsample_bylevel=None,\n",
       "                                                      colsample_bynode=None,\n",
       "                                                      colsample_bytree=None,\n",
       "                                                      gamma=None, gpu_id=None,\n",
       "                                                      importance_type='gain',\n",
       "                                                      interaction_constraints=None,\n",
       "                                                      learning_rate=None,\n",
       "                                                      max_delta_step=None,\n",
       "                                                      max_depth=None,\n",
       "                                                      min_child_weight=None,\n",
       "                                                      missing=nan,\n",
       "                                                      monotone_constraints=Non...\n",
       "              return_train_score=True,\n",
       "              search_spaces={'model__gamma': (1e-06, 10.0, 'log-uniform'),\n",
       "                             'model__learning_rate': Real(low=0.005, high=0.3, prior='uniform', transform='identity'),\n",
       "                             'model__max_depth': Integer(low=2, high=5, prior='uniform', transform='identity'),\n",
       "                             'model__n_estimators': Categorical(categories=(10, 50, 100, 200, 500), prior=None),\n",
       "                             'model__objective': ['count:poisson']})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_cb = partial(cb,filename='../Output/tuning_results_EI_exploit.csv',verbose = 1)\n",
    "opt = BayesSearchCV(\n",
    "    pipe,\n",
    "    {\n",
    "        'model__objective':['count:poisson'],\n",
    "        'model__n_estimators': Categorical([10,50,100,200,500]),\n",
    "        'model__gamma': (1e-6, 1e+1, 'log-uniform'),\n",
    "        'model__max_depth': Integer(2, 5),  # integer valued parameter\n",
    "        'model__learning_rate': Real(0.005,.3),  # categorical parameter\n",
    "    },\n",
    "    fit_params = {\n",
    "        'model__base_margin':np.log(exp_train)\n",
    "    },\n",
    "    n_iter=10,\n",
    "    cv=3,\n",
    "    return_train_score = True,\n",
    "    optimizer_kwargs = {'acq_func':'EI','acq_optimizer_kwargs' :{'xi':0.01}}\n",
    ")\n",
    "\n",
    "opt.fit(X_train,y_train,callback = my_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.7s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.7s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.7s\n",
      "Tried OrderedDict([('model__gamma', 0.14397067192398075), ('model__learning_rate', 0.24605335280057525), ('model__max_depth', 4), ('model__n_estimators', 50), ('model__objective', 'count:poisson')]), score =-0.0054757849393575996\n",
      "best score = -0.0054757849393575996 @ diff = 0.0002008655574515109\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   4.4s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   4.5s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   4.4s\n",
      "Tried OrderedDict([('model__gamma', 0.01733263899193809), ('model__learning_rate', 0.23261212860797187), ('model__max_depth', 2), ('model__n_estimators', 500), ('model__objective', 'count:poisson')]), score =-0.006833050443898713\n",
      "best score = -0.0054757849393575996 @ diff = 0.0002008655574515109\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.1s\n",
      "Tried OrderedDict([('model__gamma', 0.0010058119260874178), ('model__learning_rate', 0.1012450212552201), ('model__max_depth', 4), ('model__n_estimators', 10), ('model__objective', 'count:poisson')]), score =-7.74573412982334\n",
      "best score = -0.0054757849393575996 @ diff = 0.0002008655574515109\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.1s\n",
      "Tried OrderedDict([('model__gamma', 0.00015377641311533022), ('model__learning_rate', 0.1961684080418661), ('model__max_depth', 4), ('model__n_estimators', 10), ('model__objective', 'count:poisson')]), score =-2.9026172022926056\n",
      "best score = -0.0054757849393575996 @ diff = 0.0002008655574515109\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   3.7s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   3.7s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   3.7s\n",
      "Tried OrderedDict([('model__gamma', 0.020837728963512075), ('model__learning_rate', 0.2752076966196579), ('model__max_depth', 5), ('model__n_estimators', 200), ('model__objective', 'count:poisson')]), score =-0.006939883570117833\n",
      "best score = -0.0054757849393575996 @ diff = 0.0002008655574515109\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.8s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.3s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.8s\n",
      "Tried OrderedDict([('model__gamma', 1.4723542708845943), ('model__learning_rate', 0.16133370038252512), ('model__max_depth', 5), ('model__n_estimators', 100), ('model__objective', 'count:poisson')]), score =-0.006761688616305595\n",
      "best score = -0.0054757849393575996 @ diff = 0.0002008655574515109\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.1s\n",
      "Tried OrderedDict([('model__gamma', 1.1728154460217053), ('model__learning_rate', 0.14197120051694462), ('model__max_depth', 5), ('model__n_estimators', 10), ('model__objective', 'count:poisson')]), score =-5.089828342690827\n",
      "best score = -0.0054757849393575996 @ diff = 0.0002008655574515109\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.4s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.3s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.4s\n",
      "Tried OrderedDict([('model__gamma', 6.277277205891723), ('model__learning_rate', 0.21736558870904915), ('model__max_depth', 3), ('model__n_estimators', 200), ('model__objective', 'count:poisson')]), score =-0.0072187797765147325\n",
      "best score = -0.0054757849393575996 @ diff = 0.0002008655574515109\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.7s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.7s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.7s\n",
      "Tried OrderedDict([('model__gamma', 2.3858743021045635e-05), ('model__learning_rate', 0.2746196513836032), ('model__max_depth', 4), ('model__n_estimators', 50), ('model__objective', 'count:poisson')]), score =-0.006296001221854324\n",
      "best score = -0.0054757849393575996 @ diff = 0.0002008655574515109\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.8s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.8s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.8s\n",
      "Tried OrderedDict([('model__gamma', 0.00010122614108028208), ('model__learning_rate', 0.245058403769856), ('model__max_depth', 5), ('model__n_estimators', 100), ('model__objective', 'count:poisson')]), score =-0.00682541548091299\n",
      "best score = -0.0054757849393575996 @ diff = 0.0002008655574515109\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=3,\n",
       "              estimator=Pipeline(steps=[('model',\n",
       "                                         XGBRegressor(base_score=None,\n",
       "                                                      booster=None,\n",
       "                                                      colsample_bylevel=None,\n",
       "                                                      colsample_bynode=None,\n",
       "                                                      colsample_bytree=None,\n",
       "                                                      gamma=None, gpu_id=None,\n",
       "                                                      importance_type='gain',\n",
       "                                                      interaction_constraints=None,\n",
       "                                                      learning_rate=None,\n",
       "                                                      max_delta_step=None,\n",
       "                                                      max_depth=None,\n",
       "                                                      min_child_weight=None,\n",
       "                                                      missing=nan,\n",
       "                                                      monotone_constraints=Non...\n",
       "              return_train_score=True,\n",
       "              search_spaces={'model__gamma': (1e-06, 10.0, 'log-uniform'),\n",
       "                             'model__learning_rate': Real(low=0.005, high=0.3, prior='uniform', transform='identity'),\n",
       "                             'model__max_depth': Integer(low=2, high=5, prior='uniform', transform='identity'),\n",
       "                             'model__n_estimators': Categorical(categories=(10, 50, 100, 200, 500), prior=None),\n",
       "                             'model__objective': ['count:poisson']})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_cb = partial(cb,filename='../Output/tuning_results_PI.csv',verbose = 1)\n",
    "opt = BayesSearchCV(\n",
    "    pipe,\n",
    "    {\n",
    "        'model__objective':['count:poisson'],\n",
    "        'model__n_estimators': Categorical([10,50,100,200,500]),\n",
    "        'model__gamma': (1e-6, 1e+1, 'log-uniform'),\n",
    "        'model__max_depth': Integer(2, 5),  # integer valued parameter\n",
    "        'model__learning_rate': Real(0.005,.3),  # categorical parameter\n",
    "    },\n",
    "    fit_params = {\n",
    "        'model__base_margin':np.log(exp_train)\n",
    "    },\n",
    "    n_iter=10,\n",
    "    cv=3,\n",
    "    return_train_score = True,\n",
    "    optimizer_kwargs = {'acq_func':'PI','acq_optimizer_kwargs' :{'xi':0.05}}\n",
    ")\n",
    "\n",
    "opt.fit(X_train,y_train,callback = my_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.9s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.9s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.9s\n",
      "Tried OrderedDict([('model__gamma', 8.197817748431884), ('model__learning_rate', 0.2784637345094721), ('model__max_depth', 2), ('model__n_estimators', 100), ('model__objective', 'count:poisson')]), score =-0.007260783447614703\n",
      "best score = -0.007260783447614703 @ diff = 6.4156478946629e-05\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   3.0s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.9s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.9s\n",
      "Tried OrderedDict([('model__gamma', 1.521572253936428), ('model__learning_rate', 0.17547572092072147), ('model__max_depth', 4), ('model__n_estimators', 200), ('model__objective', 'count:poisson')]), score =-0.006958410971068219\n",
      "best score = -0.006958410971068219 @ diff = 0.00029766287536627835\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   7.5s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   7.3s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   7.4s\n",
      "Tried OrderedDict([('model__gamma', 1.2169030958314143e-06), ('model__learning_rate', 0.17051423443449062), ('model__max_depth', 4), ('model__n_estimators', 500), ('model__objective', 'count:poisson')]), score =-0.006926697952826449\n",
      "best score = -0.006926697952826449 @ diff = 0.0023619164560920733\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.7s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.7s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.7s\n",
      "Tried OrderedDict([('model__gamma', 3.704969122397628), ('model__learning_rate', 0.15971684878856687), ('model__max_depth', 4), ('model__n_estimators', 50), ('model__objective', 'count:poisson')]), score =0.00012559436785305618\n",
      "best score = 0.00012559436785305618 @ diff = 4.300095413504028e-05\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   6.3s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   5.8s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   5.9s\n",
      "Tried OrderedDict([('model__gamma', 1.304529754711009e-06), ('model__learning_rate', 0.2899886119362525), ('model__max_depth', 3), ('model__n_estimators', 500), ('model__objective', 'count:poisson')]), score =-0.006912917970415652\n",
      "best score = 0.00012559436785305618 @ diff = 4.300095413504028e-05\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   7.4s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   7.0s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   7.3s\n",
      "Tried OrderedDict([('model__gamma', 0.11285953879016077), ('model__learning_rate', 0.2929490566567476), ('model__max_depth', 4), ('model__n_estimators', 500), ('model__objective', 'count:poisson')]), score =-0.007035319908938385\n",
      "best score = 0.00012559436785305618 @ diff = 4.300095413504028e-05\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.4s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.5s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.5s\n",
      "Tried OrderedDict([('model__gamma', 0.0005944282639683576), ('model__learning_rate', 0.20988615042633293), ('model__max_depth', 2), ('model__n_estimators', 50), ('model__objective', 'count:poisson')]), score =-0.003757167467942552\n",
      "best score = 0.00012559436785305618 @ diff = 4.300095413504028e-05\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   8.3s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   8.6s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   9.3s\n",
      "Tried OrderedDict([('model__gamma', 0.7302410648063611), ('model__learning_rate', 0.14460954488963487), ('model__max_depth', 5), ('model__n_estimators', 500), ('model__objective', 'count:poisson')]), score =-0.006856932463697428\n",
      "best score = 0.00012559436785305618 @ diff = 4.300095413504028e-05\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.2s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.1s\n",
      "Tried OrderedDict([('model__gamma', 0.010500420125834478), ('model__learning_rate', 0.18117748466493935), ('model__max_depth', 4), ('model__n_estimators', 10), ('model__objective', 'count:poisson')]), score =-3.3937852488847255\n",
      "best score = 0.00012559436785305618 @ diff = 4.300095413504028e-05\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.3s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.3s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.3s\n",
      "Tried OrderedDict([('model__gamma', 0.04820202753315285), ('model__learning_rate', 0.0343646001438562), ('model__max_depth', 4), ('model__n_estimators', 100), ('model__objective', 'count:poisson')]), score =-0.5979581630486225\n",
      "best score = 0.00012559436785305618 @ diff = 4.300095413504028e-05\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=3,\n",
       "              estimator=Pipeline(steps=[('model',\n",
       "                                         XGBRegressor(base_score=None,\n",
       "                                                      booster=None,\n",
       "                                                      colsample_bylevel=None,\n",
       "                                                      colsample_bynode=None,\n",
       "                                                      colsample_bytree=None,\n",
       "                                                      gamma=None, gpu_id=None,\n",
       "                                                      importance_type='gain',\n",
       "                                                      interaction_constraints=None,\n",
       "                                                      learning_rate=None,\n",
       "                                                      max_delta_step=None,\n",
       "                                                      max_depth=None,\n",
       "                                                      min_child_weight=None,\n",
       "                                                      missing=nan,\n",
       "                                                      monotone_constraints=Non...\n",
       "              return_train_score=True,\n",
       "              search_spaces={'model__gamma': (1e-06, 10.0, 'log-uniform'),\n",
       "                             'model__learning_rate': Real(low=0.005, high=0.3, prior='uniform', transform='identity'),\n",
       "                             'model__max_depth': Integer(low=2, high=5, prior='uniform', transform='identity'),\n",
       "                             'model__n_estimators': Categorical(categories=(10, 50, 100, 200, 500), prior=None),\n",
       "                             'model__objective': ['count:poisson']})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_cb = partial(cb,filename='../Output/tuning_results_PI_exploit.csv',verbose = 1)\n",
    "opt = BayesSearchCV(\n",
    "    pipe,\n",
    "    {\n",
    "        'model__objective':['count:poisson'],\n",
    "        'model__n_estimators': Categorical([10,50,100,200,500]),\n",
    "        'model__gamma': (1e-6, 1e+1, 'log-uniform'),\n",
    "        'model__max_depth': Integer(2, 5),  # integer valued parameter\n",
    "        'model__learning_rate': Real(0.005,.3),  # categorical parameter\n",
    "    },\n",
    "    fit_params = {\n",
    "        'model__base_margin':np.log(exp_train)\n",
    "    },\n",
    "    n_iter=10,\n",
    "    cv=3,\n",
    "    return_train_score = True,\n",
    "    optimizer_kwargs = {'acq_func':'PI','acq_optimizer_kwargs' :{'xi':0.3}}\n",
    ")\n",
    "\n",
    "opt.fit(X_train,y_train,callback = my_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   3.7s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   3.6s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   3.6s\n",
      "Tried OrderedDict([('model__gamma', 0.00011265172684669811), ('model__learning_rate', 0.14362900940042944), ('model__max_depth', 5), ('model__n_estimators', 200), ('model__objective', 'count:poisson')]), score =-0.006834421291839081\n",
      "best score = -0.006834421291839081 @ diff = 0.0012286938770088504\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.6s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.6s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.6s\n",
      "Tried OrderedDict([('model__gamma', 0.0002462530820244062), ('model__learning_rate', 0.13163450851841665), ('model__max_depth', 3), ('model__n_estimators', 50), ('model__objective', 'count:poisson')]), score =-0.008180604254212779\n",
      "best score = -0.006834421291839081 @ diff = 0.0012286938770088504\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.2s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.2s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.2s\n",
      "Tried OrderedDict([('model__gamma', 0.005328860921527562), ('model__learning_rate', 0.29960117950390713), ('model__max_depth', 3), ('model__n_estimators', 100), ('model__objective', 'count:poisson')]), score =-0.006872121141692092\n",
      "best score = -0.006834421291839081 @ diff = 0.0012286938770088504\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   5.8s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   5.7s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   5.7s\n",
      "Tried OrderedDict([('model__gamma', 0.01974337907706079), ('model__learning_rate', 0.02720318223221127), ('model__max_depth', 3), ('model__n_estimators', 500), ('model__objective', 'count:poisson')]), score =-0.006385919910380257\n",
      "best score = -0.006385919910380257 @ diff = 0.00011265348459995727\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.5s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.5s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.5s\n",
      "Tried OrderedDict([('model__gamma', 1.718486151229825), ('model__learning_rate', 0.29951014601968445), ('model__max_depth', 4), ('model__n_estimators', 100), ('model__objective', 'count:poisson')]), score =-0.006937987402536354\n",
      "best score = -0.006385919910380257 @ diff = 0.00011265348459995727\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   4.5s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   4.4s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   5.0s\n",
      "Tried OrderedDict([('model__gamma', 1.6215293537622553), ('model__learning_rate', 0.06887966723520693), ('model__max_depth', 2), ('model__n_estimators', 500), ('model__objective', 'count:poisson')]), score =-0.007031399407130414\n",
      "best score = -0.006385919910380257 @ diff = 0.00011265348459995727\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.2s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.2s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.2s\n",
      "Tried OrderedDict([('model__gamma', 0.007072608463329894), ('model__learning_rate', 0.18562482257148125), ('model__max_depth', 3), ('model__n_estimators', 100), ('model__objective', 'count:poisson')]), score =-0.007022217009696963\n",
      "best score = -0.006385919910380257 @ diff = 0.00011265348459995727\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.8s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.8s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.8s\n",
      "Tried OrderedDict([('model__gamma', 1.6468657216037352), ('model__learning_rate', 0.1646028310428292), ('model__max_depth', 5), ('model__n_estimators', 50), ('model__objective', 'count:poisson')]), score =0.00021494952037884503\n",
      "best score = 0.00021494952037884503 @ diff = 0.00010782575071870414\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.2s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.2s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.2s\n",
      "Tried OrderedDict([('model__gamma', 0.0003539550858037405), ('model__learning_rate', 0.22562324895417138), ('model__max_depth', 3), ('model__n_estimators', 100), ('model__objective', 'count:poisson')]), score =-0.006949608472896193\n",
      "best score = 0.00021494952037884503 @ diff = 0.00010782575071870414\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.6s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.6s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.6s\n",
      "Tried OrderedDict([('model__gamma', 9.521809368164069e-06), ('model__learning_rate', 0.2065337009262897), ('model__max_depth', 3), ('model__n_estimators', 50), ('model__objective', 'count:poisson')]), score =-0.003260363672080828\n",
      "best score = 0.00021494952037884503 @ diff = 0.00010782575071870414\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=3,\n",
       "              estimator=Pipeline(steps=[('model',\n",
       "                                         XGBRegressor(base_score=None,\n",
       "                                                      booster=None,\n",
       "                                                      colsample_bylevel=None,\n",
       "                                                      colsample_bynode=None,\n",
       "                                                      colsample_bytree=None,\n",
       "                                                      gamma=None, gpu_id=None,\n",
       "                                                      importance_type='gain',\n",
       "                                                      interaction_constraints=None,\n",
       "                                                      learning_rate=None,\n",
       "                                                      max_delta_step=None,\n",
       "                                                      max_depth=None,\n",
       "                                                      min_child_weight=None,\n",
       "                                                      missing=nan,\n",
       "                                                      monotone_constraints=Non...\n",
       "              return_train_score=True,\n",
       "              search_spaces={'model__gamma': (1e-06, 10.0, 'log-uniform'),\n",
       "                             'model__learning_rate': Real(low=0.005, high=0.3, prior='uniform', transform='identity'),\n",
       "                             'model__max_depth': Integer(low=2, high=5, prior='uniform', transform='identity'),\n",
       "                             'model__n_estimators': Categorical(categories=(10, 50, 100, 200, 500), prior=None),\n",
       "                             'model__objective': ['count:poisson']})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_cb = partial(cb,filename='../Output/tuning_results_LCB.csv',verbose = 1)\n",
    "opt = BayesSearchCV(\n",
    "    pipe,\n",
    "    {\n",
    "        'model__objective':['count:poisson'],\n",
    "        'model__n_estimators': Categorical([10,50,100,200,500]),\n",
    "        'model__gamma': (1e-6, 1e+1, 'log-uniform'),\n",
    "        'model__max_depth': Integer(2, 5),  # integer valued parameter\n",
    "        'model__learning_rate': Real(0.005,.3),  # categorical parameter\n",
    "    },\n",
    "    fit_params = {\n",
    "        'model__base_margin':np.log(exp_train)\n",
    "    },\n",
    "    n_iter=10,\n",
    "    cv=3,\n",
    "    return_train_score = True,\n",
    "    optimizer_kwargs = {'acq_func':'LCB','acq_optimizer_kwargs' :{'kappa': 2.3263}}\n",
    ")\n",
    "\n",
    "opt.fit(X_train,y_train,callback = my_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.9s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.9s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.9s\n",
      "Tried OrderedDict([('model__gamma', 0.037500990534027424), ('model__learning_rate', 0.2547050738201449), ('model__max_depth', 4), ('model__n_estimators', 200), ('model__objective', 'count:poisson')]), score =-0.006824960080262829\n",
      "best score = -0.006824960080262829 @ diff = 0.0012921136987832415\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.9s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.9s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.9s\n",
      "Tried OrderedDict([('model__gamma', 0.030132796056755923), ('model__learning_rate', 0.048004881290200314), ('model__max_depth', 2), ('model__n_estimators', 100), ('model__objective', 'count:poisson')]), score =-0.12195773375357691\n",
      "best score = -0.006824960080262829 @ diff = 0.0012921136987832415\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   0.1s\n",
      "Tried OrderedDict([('model__gamma', 0.046634500273089685), ('model__learning_rate', 0.2038796797675753), ('model__max_depth', 2), ('model__n_estimators', 10), ('model__objective', 'count:poisson')]), score =-2.6775765411497408\n",
      "best score = -0.006824960080262829 @ diff = 0.0012921136987832415\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   3.6s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   3.6s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   3.6s\n",
      "Tried OrderedDict([('model__gamma', 0.00022759472758388568), ('model__learning_rate', 0.2262522481958126), ('model__max_depth', 5), ('model__n_estimators', 200), ('model__objective', 'count:poisson')]), score =-0.006947946258171185\n",
      "best score = -0.006824960080262829 @ diff = 0.0012921136987832415\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.9s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.9s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.9s\n",
      "Tried OrderedDict([('model__gamma', 0.4182491287909948), ('model__learning_rate', 0.11701124690129201), ('model__max_depth', 4), ('model__n_estimators', 200), ('model__objective', 'count:poisson')]), score =-0.006869970933516239\n",
      "best score = -0.006824960080262829 @ diff = 0.0012921136987832415\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.6s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.6s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.6s\n",
      "Tried OrderedDict([('model__gamma', 1.0845680121953766e-05), ('model__learning_rate', 0.0787990649252677), ('model__max_depth', 5), ('model__n_estimators', 100), ('model__objective', 'count:poisson')]), score =0.00047874289148052134\n",
      "best score = 0.00047874289148052134 @ diff = 0.000448601506245161\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.5s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.5s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.5s\n",
      "Tried OrderedDict([('model__gamma', 0.00401730389151862), ('model__learning_rate', 0.2910430621001217), ('model__max_depth', 4), ('model__n_estimators', 100), ('model__objective', 'count:poisson')]), score =-0.006830502234019204\n",
      "best score = 0.00047874289148052134 @ diff = 0.000448601506245161\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.8s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.0s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.8s\n",
      "Tried OrderedDict([('model__gamma', 0.18644094744999554), ('model__learning_rate', 0.189746396416143), ('model__max_depth', 2), ('model__n_estimators', 200), ('model__objective', 'count:poisson')]), score =-0.006857769357030185\n",
      "best score = 0.00047874289148052134 @ diff = 0.000448601506245161\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   7.3s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   7.2s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   7.3s\n",
      "Tried OrderedDict([('model__gamma', 0.0023925538273368552), ('model__learning_rate', 0.171933897911247), ('model__max_depth', 4), ('model__n_estimators', 500), ('model__objective', 'count:poisson')]), score =-0.006887417052123955\n",
      "best score = 0.00047874289148052134 @ diff = 0.000448601506245161\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.2s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.2s\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   1.2s\n",
      "Tried OrderedDict([('model__gamma', 0.0023601116755843834), ('model__learning_rate', 0.20864602523271816), ('model__max_depth', 3), ('model__n_estimators', 100), ('model__objective', 'count:poisson')]), score =-0.006981387760121946\n",
      "best score = 0.00047874289148052134 @ diff = 0.000448601506245161\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=   2.5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=3,\n",
       "              estimator=Pipeline(steps=[('model',\n",
       "                                         XGBRegressor(base_score=None,\n",
       "                                                      booster=None,\n",
       "                                                      colsample_bylevel=None,\n",
       "                                                      colsample_bynode=None,\n",
       "                                                      colsample_bytree=None,\n",
       "                                                      gamma=None, gpu_id=None,\n",
       "                                                      importance_type='gain',\n",
       "                                                      interaction_constraints=None,\n",
       "                                                      learning_rate=None,\n",
       "                                                      max_delta_step=None,\n",
       "                                                      max_depth=None,\n",
       "                                                      min_child_weight=None,\n",
       "                                                      missing=nan,\n",
       "                                                      monotone_constraints=Non...\n",
       "              return_train_score=True,\n",
       "              search_spaces={'model__gamma': (1e-06, 10.0, 'log-uniform'),\n",
       "                             'model__learning_rate': Real(low=0.005, high=0.3, prior='uniform', transform='identity'),\n",
       "                             'model__max_depth': Integer(low=2, high=5, prior='uniform', transform='identity'),\n",
       "                             'model__n_estimators': Categorical(categories=(10, 50, 100, 200, 500), prior=None),\n",
       "                             'model__objective': ['count:poisson']})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_cb = partial(cb,filename='../Output/tuning_results_LCB_exploit.csv',verbose = 1)\n",
    "opt = BayesSearchCV(\n",
    "    pipe,\n",
    "    {\n",
    "        'model__objective':['count:poisson'],\n",
    "        'model__n_estimators': Categorical([10,50,100,200,500]),\n",
    "        'model__gamma': (1e-6, 1e+1, 'log-uniform'),\n",
    "        'model__max_depth': Integer(2, 5),  # integer valued parameter\n",
    "        'model__learning_rate': Real(0.005,.3),  # categorical parameter\n",
    "    },\n",
    "    fit_params = {\n",
    "        'model__base_margin':np.log(exp_train)\n",
    "    },\n",
    "    n_iter=10,\n",
    "    cv=3,\n",
    "    return_train_score = True,\n",
    "    optimizer_kwargs = {'acq_func':'LCB','acq_optimizer_kwargs' :{'kappa': 1.38}}\n",
    ")\n",
    "\n",
    "opt.fit(X_train,y_train,callback = my_cb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes",
   "language": "python",
   "name": "bayes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
